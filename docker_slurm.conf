// singularity_slurm.conf

include required(classpath("application"))

// this stanza controls how fast Cromwell submits jobs to AWS Batch
// and avoids running into API request limits
system {
    job-rate-control {
        jobs = 1
        per = 2 second
    }
}

aws {

    application-name = "cromwell"
    
    auths = [
        {
         name = "default"
         scheme = "default"
        }
    ]
    
    region = "us-west-1"
    // uses region from ~/.aws/config set by aws configure command,
    // or us-west-1 by default
}

engine {
     filesystems {
         s3 {
            auth = "default"
         }
    }
}

backend {
     default = "Slurm"
     providers {
         Slurm {
             actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
	     config {
	        script-epilogue = "sleep 30"
	        concurrent-job-limit = 10
	        runtime-attributes = """
             	  Int rt_time = 600
             	  Int rt_cpus = 2
             	  Int rt_mem = 4000
             	  String rt_queue = "compute"
                  String? docker
             	"""
             	submit = """
             	sbatch \
                --export=ALL \
             	-J ${job_name} \
             	-D ${cwd} \
             	-o ${out} \
             	-e ${err} \
             	-t ${rt_time} \
             	-p ${rt_queue} \
             	${"-c " + rt_cpus} \
             	--wrap "/bin/bash ${script}"
             	"""

                submit-docker = """
                # Submit the script to SLURM
                sbatch \
                  --wait \
                  --export=ALL \
                  -J ${job_name} \
                  -D ${cwd} \
                  -o ${cwd}/execution/stdout \
                  -e ${cwd}/execution/stderr \
                  -t ${rt_time} \
             	  -p ${rt_queue} \
                  ${"-c " + rt_cpus} \
                  --wrap "docker run --rm -i --entrypoint /bin/bash -v ${cwd}:${docker_cwd} ${docker} < ${script}"
	        """
	        # Root directory where Cromwell writes job results.  This directory must be
                # visible and writeable by the Cromwell process as well as the jobs that Cromwell
                # launches.
                root = "/vol1/cromwell-executions"
	
                filesystems = {
                    local {
                        localization: [ "soft-link", "hard-link", "copy" ]
                    }
                    s3 {
                         // A reference to a potentially different auth for manipulating files via engine functions.
                         auth = "default"
                    }
                }
		
             	job-id-regex = "Submitted batch job (\\d+).*"
             	kill = "scancel ${job_id}"
             	check-alive = "squeue -j ${job_id}"
	     }
         }
     }
}
